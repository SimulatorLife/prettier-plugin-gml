name: Auto-merge Codex PRs

on:
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    branches: [main, master]
  push:
    branches:
      - codex/**
      - chore/auto-lint-format
  schedule:
    - cron: "0,30 * * * *"
  workflow_dispatch:
    inputs:
      confirm:
        description: "Type 'merge' to run the auto-merge sweep"
        required: false
        default: "merge"
      pr_number:
        description: "PR number to verify (optional; omit to auto-resolve from branch)"
        required: false

permissions:
  contents: write
  pull-requests: write
  checks: write
  actions: write

# Avoid overlapping runs per PR/branch
concurrency:
  group: codex-automerge-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: false

jobs:
  ###########################################################################
  # PR metadata (used by regression test gating + merges)
  ###########################################################################
  pr-meta:
    if: ${{ github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    outputs:
      number: ${{ steps.get.outputs.number }}
      changed_files: ${{ steps.get.outputs.changed_files }}
      head_ref: ${{ steps.get.outputs.head_ref }}
      base_sha: ${{ steps.get.outputs.base_sha }}
    steps:
      - name: Read PR details
        id: get
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;

            async function resolvePrNumber() {
              if (context.eventName === 'pull_request') {
                return context.payload.pull_request.number;
              }
              const inputNum = Number((context.payload.inputs?.pr_number || '').trim() || 0);
              if (inputNum) return inputNum;

              // Auto-resolve: dispatch from PR head branch
              const ref = (context.ref || '').replace('refs/heads/', '');
              if (!ref) return 0;
              const prs = await github.paginate(github.rest.pulls.list, { owner, repo, state: 'open', per_page: 100 });
              const match = prs.find(p => p.head?.ref === ref);
              return match?.number || 0;
            }

            const n = await resolvePrNumber();
            if (!n) {
              core.setFailed('pr-meta: Could not determine PR number. Provide inputs.pr_number or dispatch from the PR head branch.');
              return;
            }

            const { data: pr } = await github.rest.pulls.get({ owner, repo, pull_number: n });

            core.setOutput('number', String(n));
            core.setOutput('changed_files', String(pr.changed_files || 0));
            core.setOutput('head_ref', pr.head.ref);
            core.setOutput('base_sha', pr.base.sha);
            core.notice(`PR #${n}: changed_files=${pr.changed_files || 0}, head_ref=${pr.head.ref}, base_sha=${pr.base.sha}`);

  ###########################################################################
  # Regression detection (always creates/checks a job; fast-passes when no changes)
  ###########################################################################
  regression-tests:
    if: ${{ github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    needs: pr-meta
    name: Detect new test failures (allow legacy failures)
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      # Fast-pass when PR has no file changes (produces a green job)
      - name: No changes — fast pass
        if: ${{ needs.pr-meta.outputs.changed_files == '0' }}
        uses: actions/github-script@v7
        with:
          script: |
            core.notice('PR has 0 changed files — skipping tests and marking regression-tests as passed.');
            // Nothing else to do; remaining steps are guarded by "changed_files != 0".

      # === BASE (merge target) ===
      - name: Checkout base (merge target)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.pr-meta.outputs.base_sha }}
          path: base

      - name: Setup Node (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: base/package-lock.json

      - name: Install deps (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: npm ci

      - name: Prepare test result directory (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: |
          rm -rf test-results
          mkdir -p test-results

      - name: Run shared tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: |
          mkdir -p test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=./test-results/shared.xml \
            --test-reporter=tap   --test-reporter-destination=./test-results/shared.tap \
            src/shared/tests/*.test.js
        continue-on-error: true

      - name: Run parser tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/parser
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/parser.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/parser.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run plugin tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/plugin
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/plugin.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/plugin.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run CLI tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/cli
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/cli.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/cli.tap \
            tests/*.test.js
        continue-on-error: true

      # === HEAD (PR) at workspace root ===
      - name: Checkout head (PR)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.pr-meta.outputs.head_ref }}

      - name: Setup Node (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install deps (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: npm ci

      - name: Prepare test result directory (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          rm -rf test-results
          mkdir -p test-results

      - name: Run shared tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          mkdir -p test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=./test-results/shared.xml \
            --test-reporter=tap   --test-reporter-destination=./test-results/shared.tap \
            src/shared/tests/*.test.js
        continue-on-error: true

      - name: Run parser tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/parser
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/parser.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/parser.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run plugin tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/plugin
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/plugin.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/plugin.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run CLI tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/cli
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/cli.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/cli.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Install compare script dependency
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: npm install --no-save fast-xml-parser@^4

      - name: Compare JUnit results (fail only on regressions)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          cat <<'EOF' > compare-junit.mjs
          import fs from 'node:fs';
          import path from 'node:path';
          import { XMLParser } from 'fast-xml-parser';

          function readCases(rootDir) {
            const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '' });
            const results = new Map();
            const resultsDir = path.join(rootDir, 'test-results');
            if (!fs.existsSync(resultsDir)) return results;

            const files = fs.readdirSync(resultsDir).filter(f => f.endsWith('.xml'));
            for (const file of files) {
              const xml = fs.readFileSync(path.join(resultsDir, file), 'utf8');
              const data = parser.parse(xml);
              const suites = [];
              if (data.testsuites && Array.isArray(data.testsuites.testsuite)) { suites.push(...data.testsuites.testsuite); }
              else if (data.testsuite) { suites.push(data.testsuite); }
              else if (Array.isArray(data.testsuites)) { suites.push(...data.testsuites); }

              for (const suite of suites) {
                const cases = suite.testcase ? (Array.isArray(suite.testcase) ? suite.testcase : [suite.testcase]) : [];
                for (const tc of cases) {
                  const name = String(tc.name ?? '');
                  const cls = String(tc.classname ?? suite.name ?? '');
                  const key = cls + ' :: ' + name;
                  let status = 'passed';
                  if (tc.skipped !== undefined) status = 'skipped';
                  if (tc.error !== undefined || tc.errors !== undefined) status = 'failed';
                  if (tc.failure !== undefined || tc.failures !== undefined) status = 'failed';
                  results.set(key, status);
                }
              }
            }
            return results;
          }

          const base = readCases('base');
          const head = readCases('.');
          const regressions = [];

          for (const [key, headStatus] of head.entries()) {
            const baseStatus = base.get(key);
            if (baseStatus === undefined) continue; // new test -> ignore even if failing
            if ((baseStatus === 'passed' || baseStatus === 'skipped') && headStatus === 'failed') {
              regressions.push({ test: key, from: baseStatus, to: headStatus });
            }
          }

          if (regressions.length) {
            console.log('New failing tests detected (compared to base):');
            for (const r of regressions) console.log('- ' + r.test + ' (' + r.from + ' -> ' + r.to + ')');
            process.exit(1);
          } else {
            console.log('No new failing tests compared to base.');
          }
          EOF
          node compare-junit.mjs
        shell: bash

      - name: Publish PR test summary (head only)
        if: always()
        uses: dorny/test-reporter@v2
        with:
          name: Node.js test results (PR head)
          path: test-results/*.xml
          reporter: java-junit
          fail-on-error: false
          use-actions-summary: true

      # 👇 Adds/updates a sticky PR comment with a concise summary & failures
      - name: Comment test results on PR (sticky)
        if: always() && github.event_name == 'pull_request'
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: |
            test-results/**/*.xml
          check_name: Node.js test results (PR head)
          comment_mode: update    # keep a single up-to-date comment
          compare_to_earlier_commit: true

      # 👇 Attach raw reports so anyone can download/open them from the PR
      - name: Upload test reports as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: junit-and-tap-${{ github.sha }}
          path: |
            test-results/*.xml
            test-results/*.tap
          retention-days: 7

  ###########################################################################
  # Auto-merge on PR events (re-run regression if needed for current SHA)
  ###########################################################################
  auto-merge-pr:
    if: ${{ github.event_name == 'pull_request' }}
    needs: [pr-meta, regression-tests]
    runs-on: ubuntu-latest
    steps:
      - name: Require green regression (or run it), then merge
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const n     = Number('${{ needs.pr-meta.outputs.number }}');

            const REQUIRED_RUN_NAME = 'Detect new test failures (allow legacy failures)';
            const WORKFLOW_FILE = '.github/workflows/codex-automerge-prs.yml';
            const POLL_MS = 10000;
            const TIMEOUT_MS = 20 * 60 * 1000;

            const { data: pr } = await github.rest.pulls.get({ owner, repo, pull_number: n });

            if (pr.draft) {
              core.notice(`Skip merge #${n}: draft.`);
              return;
            }
            const state = String(pr.mergeable_state || '').toLowerCase();
            if (pr.mergeable !== true || !['clean','unstable'].includes(state)) {
              core.notice(`Skip merge #${n}: mergeable=${pr.mergeable}, state=${state}.`);
              return;
            }

            const changedFiles = Number(pr.changed_files || 0);
            const sha = pr.head.sha;

            async function hasGreenRegression(refSha) {
              const { data: checks } = await github.rest.checks.listForRef({ owner, repo, ref: refSha, per_page: 100 });
              return checks.check_runs.some(run =>
                run.name === REQUIRED_RUN_NAME && run.status === 'completed' && run.conclusion === 'success'
              );
            }

            if (changedFiles > 0) {
              if (!(await hasGreenRegression(sha))) {
                core.notice(`No passing "${REQUIRED_RUN_NAME}" for ${sha}. Dispatching regression run...`);
                await github.rest.actions.createWorkflowDispatch({
                  owner, repo, workflow_id: WORKFLOW_FILE,
                  ref: pr.head.ref,
                  inputs: { pr_number: String(n) }
                });

                const deadline = Date.now() + TIMEOUT_MS;
                while (Date.now() < deadline) {
                  await new Promise(r => setTimeout(r, POLL_MS));
                  if (await hasGreenRegression(sha)) {
                    core.notice(`Regression passed for ${sha}.`);
                    break;
                  }
                }
                if (!(await hasGreenRegression(sha))) {
                  core.notice(`Skip merge #${n}: regression did not pass (or timed out) for ${sha}.`);
                  return;
                }
              }
            } else {
              core.info(`PR #${n} has no file changes; regression tests not required.`);
            }

            // Merge
            await github.rest.pulls.merge({ owner, repo, pull_number: n, merge_method: 'squash' });
            core.notice(`Auto-merged PR #${n}.`);

            // Delete head branch if safe
            try {
              const headRef = pr.head?.ref;
              const headRepoFull = pr.head?.repo?.full_name?.toLowerCase() || '';
              const thisFull = `${owner}/${repo}`.toLowerCase();
              if (!headRef || headRepoFull !== thisFull) {
                core.info(`Not deleting branch: different repo or missing ref (head=${headRepoFull}, this=${thisFull}, ref=${headRef}).`);
              } else {
                const { data: rinfo } = await github.rest.repos.get({ owner, repo });
                const defaultBranch = rinfo.default_branch;
                if (headRef === defaultBranch) {
                  core.info(`Not deleting branch: ${headRef} is the default branch.`);
                } else {
                  await github.rest.git.deleteRef({ owner, repo, ref: `heads/${headRef}` });
                  core.notice(`Deleted branch ${headRef} after merge.`);
                }
              }
            } catch (e) {
              core.warning(`Unable to delete head branch: ${e.message}`);
            }

  ###########################################################################
  # Scheduled / manual sweep (includes re-running regression if needed)
  ###########################################################################
  scheduled-automerge:
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && (startsWith(github.ref, 'refs/heads/codex/') || github.ref == 'refs/heads/chore/auto-lint-format')) }}
    runs-on: ubuntu-latest
    steps:
      - name: Merge eligible open PRs (run regression if needed)
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const REQUIRED_RUN_NAME = 'Detect new test failures (allow legacy failures)';
            const WORKFLOW_FILE = '.github/workflows/codex-automerge-prs.yml';
            const acceptableStates = new Set(['clean','unstable']);
            const POLL_MS = 10000;
            const TIMEOUT_MS = 20 * 60 * 1000;

            // If manual, require confirm unless we're targeting a specific PR via input
            const trigger = context.eventName;
            const inputs  = context.payload?.inputs || {};
            const confirm = String(inputs?.confirm || '').trim().toLowerCase();

            if (trigger === 'workflow_dispatch' && !inputs?.pr_number && confirm !== 'merge') {
              core.notice('Skipping auto-merge sweep: confirmation keyword not provided.');
              return;
            }

            const merged = [];
            const skipped = [];

            const openPRs = await github.paginate(
              github.rest.pulls.list,
              { owner, repo, state: 'open', per_page: 100, sort: 'updated', direction: 'desc' }
            );

            async function hasGreenRegression(refSha) {
              const { data: checks } = await github.rest.checks.listForRef({ owner, repo, ref: refSha, per_page: 100 });
              return checks.check_runs.some(run =>
                run.name === REQUIRED_RUN_NAME && run.status === 'completed' && run.conclusion === 'success'
              );
            }

            for (const pr of openPRs) {
              try {
                const { data: full } = await github.rest.pulls.get({ owner, repo, pull_number: pr.number });

                if (full.draft) { skipped.push({ number: pr.number, reason: 'draft' }); continue; }

                const state = String(full.mergeable_state || '').toLowerCase();
                if (full.mergeable !== true || !acceptableStates.has(state)) {
                  skipped.push({ number: pr.number, reason: `not mergeable: ${state}` });
                  continue;
                }

                const changedFiles = Number(full.changed_files || 0);
                const sha = full.head.sha;

                if (changedFiles > 0 && !(await hasGreenRegression(sha))) {
                  core.info(`#${full.number}: no passing "${REQUIRED_RUN_NAME}" for ${sha}; dispatching...`);
                  await github.rest.actions.createWorkflowDispatch({
                    owner, repo, workflow_id: WORKFLOW_FILE,
                    ref: full.head.ref,
                    inputs: { pr_number: String(full.number) }
                  });

                  const deadline = Date.now() + TIMEOUT_MS;
                  let ok = false;
                  while (Date.now() < deadline) {
                    await new Promise(r => setTimeout(r, POLL_MS));
                    if (await hasGreenRegression(sha)) { ok = true; break; }
                  }
                  if (!ok) {
                    skipped.push({ number: pr.number, reason: 'regression not green (timeout/fail)' });
                    continue;
                  }
                }

                // Merge
                await github.rest.pulls.merge({ owner, repo, pull_number: pr.number, merge_method: 'squash' });
                merged.push(pr.number);

                // Delete head branch if safe
                try {
                  const headRef = full.head?.ref;
                  const headRepoFull = full.head?.repo?.full_name?.toLowerCase() || '';
                  const thisFull = `${owner}/${repo}`.toLowerCase();
                  if (!headRef || headRepoFull !== thisFull) {
                    core.info(`#${full.number}: not deleting branch — different repo or missing ref (head=${headRepoFull}, this=${thisFull}, ref=${headRef}).`);
                  } else {
                    const { data: rinfo } = await github.rest.repos.get({ owner, repo });
                    const defaultBranch = rinfo.default_branch;
                    if (headRef === defaultBranch) {
                      core.info(`#${full.number}: not deleting branch — ${headRef} is default branch.`);
                    } else {
                      await github.rest.git.deleteRef({ owner, repo, ref: `heads/${headRef}` });
                      core.notice(`#${full.number}: deleted branch ${headRef} after merge.`);
                    }
                  }
                } catch (e) {
                  core.warning(`#${full.number}: unable to delete head branch: ${e.message}`);
                }

              } catch (e) {
                core.warning(`Failed to auto-merge PR #${pr.number}: ${e.message}`);
                skipped.push({ number: pr.number, reason: 'exception' });
              }
            }

            core.notice(`Scheduled auto-merge complete. Merged ${merged.length} PR(s): ${merged.join(', ') || 'none'}.`);
            if (skipped.length) {
              const breakdown = skipped.map(s => `#${s.number} (${s.reason})`).join(', ');
              core.info('Skipped PRs: ' + breakdown);
            }
