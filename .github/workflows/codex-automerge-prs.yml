name: Auto-merge Codex PRs

on:
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    branches: [main, master]
  push:
    branches:
      - codex/**
      - chore/auto-lint-format
  workflow_dispatch:
    inputs:
      pr_number:
        description: "PR number to verify (optional; omit to auto-resolve from branch)"
        required: false

permissions:
  contents: write
  pull-requests: write
  checks: write
  actions: write

# Avoid overlapping runs per PR/branch
concurrency:
  group: codex-automerge-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: false

jobs:
  ###########################################################################
  # PR metadata (used by regression test gating + merges)
  ###########################################################################
  pr-meta:
    if: ${{ github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    outputs:
      number: ${{ steps.get.outputs.number }}
      changed_files: ${{ steps.get.outputs.changed_files }}
      head_ref: ${{ steps.get.outputs.head_ref }}
      base_sha: ${{ steps.get.outputs.base_sha }}
    steps:
      - name: Read PR details
        id: get
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;

            async function resolvePrNumber() {
              if (context.eventName === 'pull_request') {
                return context.payload.pull_request.number;
              }
              const inputNum = Number((context.payload.inputs?.pr_number || '').trim() || 0);
              if (inputNum) return inputNum;

              // Auto-resolve: dispatch from PR head branch
              const ref = (context.ref || '').replace('refs/heads/', '');
              if (!ref) return 0;
              const prs = await github.paginate(github.rest.pulls.list, { owner, repo, state: 'open', per_page: 100 });
              const match = prs.find(p => p.head?.ref === ref);
              return match?.number || 0;
            }

            const n = await resolvePrNumber();
            if (!n) {
              core.setFailed('pr-meta: Could not determine PR number. Provide inputs.pr_number or dispatch from the PR head branch.');
              return;
            }

            const { data: pr } = await github.rest.pulls.get({ owner, repo, pull_number: n });

            core.setOutput('number', String(n));
            core.setOutput('changed_files', String(pr.changed_files || 0));
            core.setOutput('head_ref', pr.head.ref);
            core.setOutput('base_sha', pr.base.sha);
            core.notice(`PR #${n}: changed_files=${pr.changed_files || 0}, head_ref=${pr.head.ref}, base_sha=${pr.base.sha}`);

  ###########################################################################
  # Regression detection (always creates/checks a job; fast-passes when no changes)
  ###########################################################################
  regression-tests:
    if: ${{ github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    needs: pr-meta
    name: Detect new test failures (allow legacy failures)
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      # Fast-pass when PR has no file changes (produces a green job)
      - name: No changes â€” fast pass
        if: ${{ needs.pr-meta.outputs.changed_files == '0' }}
        uses: actions/github-script@v7
        with:
          script: |
            core.notice('PR has 0 changed files â€” skipping tests and marking regression-tests as passed.');
            // Nothing else to do; remaining steps are guarded by "changed_files != 0".

      # === BASE (merge target) ===
      - name: Checkout base (merge target)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.pr-meta.outputs.base_sha }}
          path: base

      - name: Setup Node (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: base/package-lock.json

      - name: Install deps (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: npm ci

      - name: Prepare test result directory (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: |
          rm -rf test-results
          mkdir -p test-results

      - name: Run shared tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base
        run: |
          mkdir -p test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=./test-results/shared.xml \
            --test-reporter=tap   --test-reporter-destination=./test-results/shared.tap \
            src/shared/tests/*.test.js
        continue-on-error: true

      - name: Run parser tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/parser
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/parser.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/parser.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run plugin tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/plugin
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/plugin.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/plugin.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run CLI tests (base)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: base/src/cli
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/cli.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/cli.tap \
            tests/*.test.js
        continue-on-error: true

      # === HEAD (PR) at workspace root ===
      - name: Checkout head (PR)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.pr-meta.outputs.head_ref }}

      - name: Setup Node (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install deps (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: npm ci

      - name: Prepare test result directory (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          rm -rf test-results
          mkdir -p test-results

      - name: Run shared tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          mkdir -p test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=./test-results/shared.xml \
            --test-reporter=tap   --test-reporter-destination=./test-results/shared.tap \
            src/shared/tests/*.test.js
        continue-on-error: true

      - name: Run parser tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/parser
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/parser.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/parser.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run plugin tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/plugin
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/plugin.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/plugin.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Run CLI tests (head)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        working-directory: src/cli
        run: |
          mkdir -p ../../test-results
          node --test \
            --test-reporter=junit --test-reporter-destination=../../test-results/cli.xml \
            --test-reporter=tap   --test-reporter-destination=../../test-results/cli.tap \
            tests/*.test.js
        continue-on-error: true

      - name: Install compare script dependency
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: npm install --no-save fast-xml-parser@^4

      - name: Compare JUnit results (fail only on regressions)
        if: ${{ needs.pr-meta.outputs.changed_files != '0' }}
        run: |
          cat <<'EOF' > compare-junit.mjs
          import fs from 'node:fs';
          import path from 'node:path';
          import { XMLParser } from 'fast-xml-parser';

          function readCases(rootDir) {
            const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '' });
            const results = new Map();
            const resultsDir = path.join(rootDir, 'test-results');
            if (!fs.existsSync(resultsDir)) return results;

            const files = fs.readdirSync(resultsDir).filter(f => f.endsWith('.xml'));
            for (const file of files) {
              const xml = fs.readFileSync(path.join(resultsDir, file), 'utf8');
              const data = parser.parse(xml);
              const suites = [];
              if (data.testsuites && Array.isArray(data.testsuites.testsuite)) { suites.push(...data.testsuites.testsuite); }
              else if (data.testsuite) { suites.push(data.testsuite); }
              else if (Array.isArray(data.testsuites)) { suites.push(...data.testsuites); }

              for (const suite of suites) {
                const cases = suite.testcase ? (Array.isArray(suite.testcase) ? suite.testcase : [suite.testcase]) : [];
                for (const tc of cases) {
                  const name = String(tc.name ?? '');
                  const cls = String(tc.classname ?? suite.name ?? '');
                  const key = cls + ' :: ' + name;
                  let status = 'passed';
                  if (tc.skipped !== undefined) status = 'skipped';
                  if (tc.error !== undefined || tc.errors !== undefined) status = 'failed';
                  if (tc.failure !== undefined || tc.failures !== undefined) status = 'failed';
                  results.set(key, status);
                }
              }
            }
            return results;
          }

          const base = readCases('base');
          const head = readCases('.');
          const regressions = [];

          for (const [key, headStatus] of head.entries()) {
            const baseStatus = base.get(key);
            if (baseStatus === undefined) continue; // new test -> ignore even if failing
            if ((baseStatus === 'passed' || baseStatus === 'skipped') && headStatus === 'failed') {
              regressions.push({ test: key, from: baseStatus, to: headStatus });
            }
          }

          if (regressions.length) {
            console.log('New failing tests detected (compared to base):');
            for (const r of regressions) console.log('- ' + r.test + ' (' + r.from + ' -> ' + r.to + ')');
            process.exit(1);
          } else {
            console.log('No new failing tests compared to base.');
          }
          EOF
          node compare-junit.mjs
        shell: bash

      - name: Publish PR test summary (head only)
        if: ${{ always() && needs.pr-meta.outputs.changed_files != '0' }}
        continue-on-error: true
        uses: dorny/test-reporter@v2
        with:
          name: Node.js test results (PR head)
          path: test-results/*.xml
          reporter: java-junit
          fail-on-error: false
          fail-on-empty: false
          use-actions-summary: true

      # ðŸ‘‡ Adds/updates a sticky PR comment with a concise summary & failures
      - name: Comment summarized test results on PR (sticky)
        if: ${{ always() && github.event_name == 'pull_request' && needs.pr-meta.outputs.changed_files != '0' }}
        continue-on-error: true
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ needs.pr-meta.outputs.number }}
        with:
          script: |
            const fs = require('node:fs');
            const path = require('node:path');

            let XMLParser;
            try {
              const resolved = require.resolve('fast-xml-parser', {
                paths: [
                  process.cwd(),
                  process.env.GITHUB_WORKSPACE || '',
                ].filter(Boolean),
              });
              ({ XMLParser } = require(resolved));
            } catch (error) {
              core.warning(`fast-xml-parser is unavailable: ${error.message}`);
            }

            const marker = '<!-- codex-automerge-pr-test-summary -->';
            const prNumber = Number(process.env.PR_NUMBER || 0);
            if (!prNumber) {
              core.warning('Cannot determine PR number for summary comment.');
              return;
            }

            const pr = context.payload.pull_request || {};
            const baseLabel = `${pr.base?.ref || 'base'} @ ${(pr.base?.sha || '').slice(0, 7) || '???????'}`;
            const headLabel = `${pr.head?.ref || 'head'} @ ${(pr.head?.sha || context.sha || '').slice(0, 7) || '???????'}`;

            function collectSuiteStats(dir) {
              const resultsDir = path.join(process.cwd(), dir);
              const totals = { tests: 0, passed: 0, failed: 0, skipped: 0, time: 0 };
              const notes = [];

              if (!XMLParser) {
                notes.push('fast-xml-parser dependency is missing; cannot summarize results.');
                return { available: false, totals, notes };
              }
              if (!fs.existsSync(resultsDir)) {
                notes.push(`No directory found at ${dir}.`);
                return { available: false, totals, notes };
              }

              const files = fs.readdirSync(resultsDir).filter(f => f.endsWith('.xml'));
              if (files.length === 0) {
                notes.push(`No JUnit XML files found in ${dir}.`);
                return { available: false, totals, notes };
              }

              const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '' });

              const suiteList = [];
              const seenSuites = new Set();
              const visitNode = (node) => {
                if (!node || typeof node !== 'object') return;
                if (Array.isArray(node)) {
                  for (const child of node) visitNode(child);
                  return;
                }
                const hasCases = Object.prototype.hasOwnProperty.call(node, 'testcase');
                const hasCounts = Object.prototype.hasOwnProperty.call(node, 'tests');
                const hasNestedSuites = Object.prototype.hasOwnProperty.call(node, 'testsuite');
                const shouldRecord = hasCases || (!hasNestedSuites && hasCounts);
                if (shouldRecord && !seenSuites.has(node)) {
                  seenSuites.add(node);
                  suiteList.push(node);
                }
                for (const value of Object.values(node)) visitNode(value);
              };

              for (const file of files) {
                try {
                  const xml = fs.readFileSync(path.join(resultsDir, file), 'utf8');
                  if (!xml.trim()) continue;
                  const data = parser.parse(xml);
                  visitNode(data);
                } catch (error) {
                  notes.push(`Failed to parse ${path.join(dir, file)}: ${error.message}`);
                }
              }

              if (suiteList.length === 0) {
                notes.push(`No test suites discovered in ${dir}.`);
                return { available: false, totals, notes };
              }

              for (const suite of suiteList) {
                const rawCases = suite.testcase;
                const cases = rawCases ? (Array.isArray(rawCases) ? rawCases : [rawCases]) : [];
                if (cases.length > 0) {
                  let recordedTime = false;
                  for (const tc of cases) {
                    if (!tc || typeof tc !== 'object') continue;
                    totals.tests += 1;
                    const hasFailure = tc.failure !== undefined || tc.failures !== undefined || tc.error !== undefined || tc.errors !== undefined;
                    const isSkipped = tc.skipped !== undefined;
                    if (hasFailure) {
                      totals.failed += 1;
                    } else if (isSkipped) {
                      totals.skipped += 1;
                    } else {
                      totals.passed += 1;
                    }
                    const caseTime = Number.parseFloat(tc.time ?? tc.duration ?? tc.elapsed ?? 0);
                    if (Number.isFinite(caseTime)) {
                      totals.time += caseTime;
                      recordedTime = true;
                    }
                  }
                  if (!recordedTime) {
                    const suiteTime = Number.parseFloat(suite.time ?? 0);
                    if (Number.isFinite(suiteTime)) {
                      totals.time += suiteTime;
                    }
                  }
                } else {
                  const tests = Number.parseInt(suite.tests ?? 0, 10);
                  const failures = Number.parseInt(suite.failures ?? 0, 10) + Number.parseInt(suite.errors ?? 0, 10);
                  const skipped = Number.parseInt(suite.skipped ?? 0, 10);
                  if (Number.isFinite(tests)) totals.tests += tests;
                  if (Number.isFinite(failures)) totals.failed += failures;
                  if (Number.isFinite(skipped)) totals.skipped += skipped;
                  const inferredPassed = tests - failures - skipped;
                  if (Number.isFinite(inferredPassed) && inferredPassed > 0) {
                    totals.passed += inferredPassed;
                  }
                  const suiteTime = Number.parseFloat(suite.time ?? 0);
                  if (Number.isFinite(suiteTime)) {
                    totals.time += suiteTime;
                  }
                }
              }

              return { available: true, totals, notes };
            }

            const baseSummary = collectSuiteStats(path.join('base', 'test-results'));
            const headSummary = collectSuiteStats('test-results');

            const formatDuration = (seconds) => {
              if (!Number.isFinite(seconds) || seconds < 0) return 'â€”';
              if (seconds === 0) return '0s';
              if (seconds < 1) return `${(seconds * 1000).toFixed(0)}ms`;
              if (seconds >= 60) {
                const minutes = Math.floor(seconds / 60);
                const rem = seconds - minutes * 60;
                return `${minutes}m ${rem.toFixed(1)}s`;
              }
              return `${seconds.toFixed(2)}s`;
            };

            const formatRow = (label, summary) => {
              if (!summary.available || summary.totals.tests === 0) {
                return `| ${label} | â€” | â€” | â€” | â€” |`;
              }
              const { passed, failed, skipped, time } = summary.totals;
              return `| ${label} | ${passed} | ${failed} | ${skipped} | ${formatDuration(time)} |`;
            };

            const lines = [
              marker,
              '### Node.js regression test summary',
              '',
              '| Target | Passed | Failed | Skipped | Duration |',
              '| --- | ---: | ---: | ---: | ---: |',
              formatRow(`Base (${baseLabel})`, baseSummary),
              formatRow(`PR (${headLabel})`, headSummary),
              '',
              '_Durations are aggregated from reported test case timings._'
            ];

            const notes = [...baseSummary.notes, ...headSummary.notes];
            if (notes.length) {
              lines.push('', ...notes.map(n => `> âš ï¸ ${n}`));
            }

            const body = lines.join('\n');

            const owner = context.repo.owner;
            const repo = context.repo.repo;

            const comments = await github.paginate(github.rest.issues.listComments, {
              owner,
              repo,
              issue_number: prNumber,
              per_page: 100,
            });
            const existing = comments.find(c => c.body && c.body.includes(marker));

            if (existing) {
              await github.rest.issues.updateComment({
                owner,
                repo,
                comment_id: existing.id,
                body,
              });
              core.notice('Updated existing test summary comment.');
            } else {
              await github.rest.issues.createComment({
                owner,
                repo,
                issue_number: prNumber,
                body,
              });
              core.notice('Created new test summary comment.');
            }

      # ðŸ‘‡ Attach raw reports so anyone can download/open them from the PR
      - name: Upload test reports as artifacts
        if: ${{ always() && needs.pr-meta.outputs.changed_files != '0' }}
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: junit-and-tap-${{ github.sha }}
          path: |
            test-results/*.xml
            test-results/*.tap
          retention-days: 7

  ###########################################################################
  # Auto-merge on PR events (re-run regression if needed for current SHA)
  ###########################################################################
  auto-merge-pr:
    if: ${{ github.event_name == 'pull_request' && needs.pr-meta.outputs.changed_files != '0' }}
    needs: [pr-meta, regression-tests]
    runs-on: ubuntu-latest
    steps:
      - name: Require green regression (or run it), then merge
        uses: actions/github-script@v7
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const n     = Number('${{ needs.pr-meta.outputs.number }}');
            const REQUIRED_RUN_NAME = 'Detect new test failures (allow legacy failures)';
            const WORKFLOW_FILE = '.github/workflows/codex-automerge-prs.yml';
            const POLL_MS = 10000;
            const TIMEOUT_MS = 20 * 60 * 1000;

            const { data: pr } = await github.rest.pulls.get({ owner, repo, pull_number: n });

            if (pr.draft) {
              core.notice(`Skip merge #${n}: draft.`);
              return;
            }
            const state = String(pr.mergeable_state || '').toLowerCase();
            if (pr.mergeable !== true || !['clean','unstable'].includes(state)) {
              core.notice(`Skip merge #${n}: mergeable=${pr.mergeable}, state=${state}.`);
              return;
            }

            const changedFiles = Number(pr.changed_files || 0);
            const sha = pr.head.sha;

            async function hasGreenRegression(refSha) {
              const { data: checks } = await github.rest.checks.listForRef({ owner, repo, ref: refSha, per_page: 100 });
              return checks.check_runs.some(run =>
                run.name === REQUIRED_RUN_NAME && run.status === 'completed' && run.conclusion === 'success'
              );
            }

            if (changedFiles > 0) {
              if (!(await hasGreenRegression(sha))) {
                core.notice(`No passing "${REQUIRED_RUN_NAME}" for ${sha}. Dispatching regression run...`);
                await github.rest.actions.createWorkflowDispatch({
                  owner, repo, workflow_id: WORKFLOW_FILE,
                  ref: pr.head.ref,
                  inputs: { pr_number: String(n) }
                });

                const deadline = Date.now() + TIMEOUT_MS;
                while (Date.now() < deadline) {
                  await new Promise(r => setTimeout(r, POLL_MS));
                  if (await hasGreenRegression(sha)) {
                    core.notice(`Regression passed for ${sha}.`);
                    break;
                  }
                }
                if (!(await hasGreenRegression(sha))) {
                  core.notice(`Skip merge #${n}: regression did not pass (or timed out) for ${sha}.`);
                  return;
                }
              }
            } else {
              core.info(`PR #${n} has no file changes; regression tests not required.`);
            }

            // Merge
            await github.rest.pulls.merge({ owner, repo, pull_number: n, merge_method: 'squash' });
            core.notice(`Auto-merged PR #${n}.`);

            // Delete head branch if safe
            try {
              const headRef = pr.head?.ref;
              const headRepoFull = pr.head?.repo?.full_name?.toLowerCase() || '';
              const thisFull = `${owner}/${repo}`.toLowerCase();
              if (!headRef || headRepoFull !== thisFull) {
                core.info(`Not deleting branch: different repo or missing ref (head=${headRepoFull}, this=${thisFull}, ref=${headRef}).`);
              } else {
                const { data: rinfo } = await github.rest.repos.get({ owner, repo });
                const defaultBranch = rinfo.default_branch;
                if (headRef === defaultBranch) {
                  core.info(`Not deleting branch: ${headRef} is the default branch.`);
                } else {
                  await github.rest.git.deleteRef({ owner, repo, ref: `heads/${headRef}` });
                  core.notice(`Deleted branch ${headRef} after merge.`);
                }
              }
            } catch (e) {
              core.warning(`Unable to delete head branch: ${e.message}`);
            }
