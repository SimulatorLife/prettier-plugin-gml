name: Auto-merge PRs

on:
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    branches: [main, master, mainline]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  checks: write

concurrency:
  group: automerge-${{ github.event.pull_request.number || 'manual' }}
  cancel-in-progress: true

jobs:
  gate:
    runs-on: ubuntu-latest
    outputs:
      should_run_tests: ${{ steps.decide.outputs.should_run_tests }}
    steps:
      - id: decide
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const n = context.payload.pull_request?.number;
            if (!n) { core.setOutput('should_run_tests', 'false'); return; }
            const files = await github.paginate(github.rest.pulls.listFiles, {
              owner, repo, pull_number: n, per_page: 100
            });
            core.notice(`PR changed files: ${files.length}`);
            core.setOutput('should_run_tests', files.length > 0 ? 'true' : 'false');

  tests:
    needs: gate
    if: ${{ needs.gate.outputs.should_run_tests == 'true' }}   # <- job-level gate (will show Skipped)
    name: Run tests (${{ matrix.target }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        target: [base, head, merge]

    steps:
      - name: Resolve ref for ${{ matrix.target }}
        id: ref
        run: |
          if [ "${{ matrix.target }}" = "base" ]; then
            echo "ref=${{ github.event.pull_request.base.sha }}" >> "$GITHUB_OUTPUT"
          elif [ "${{ matrix.target }}" = "head" ]; then
            echo "ref=${{ github.sha }}" >> "$GITHUB_OUTPUT"
          else
            echo "ref=refs/pull/${{ github.event.pull_request.number }}/merge" >> "$GITHUB_OUTPUT"
          fi

      # If the synthetic merge ref doesn't exist, continue so the leg can still upload nothing and be summarized.
      - name: Checkout (${{ matrix.target }})
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.ref.outputs.ref }}
        continue-on-error: ${{ matrix.target == 'merge' }}

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install deps
        run: npm ci
        continue-on-error: ${{ matrix.target == 'merge' }}

      # Your npm script should create ./test-results/*.xml and NOT hard-exit early
      - name: Run test suite (JUnit XML)
        run: npm run test:report
        continue-on-error: true

      - name: Run coverage (LCOV)
        run: npm run test:coverage
        continue-on-error: true

      - name: Publish test summary (${{ matrix.target }})
        if: ${{ always() }}
        uses: dorny/test-reporter@v2
        with:
          name: Publish test summary (${{ matrix.target }})
          path: test-results/*.xml
          reporter: java-junit
          fail-on-error: false
          fail-on-empty: false
          use-actions-summary: false

      - name: Run lint (checkstyle)
        run: npm run lint:report
        continue-on-error: true

      - name: Upload JUnit artifacts (${{ matrix.target }})
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: junit-${{ matrix.target }}
          path: |
            test-results/*.xml
            test-results/lcov.info
          retention-days: 7

  summarize:
    name: Summarize & comment table
    needs: tests
    runs-on: ubuntu-latest
    outputs:
      all_green: ${{ steps.regress.outputs.all_green }}
    env:
      GH_USER_TOKEN: ${{ secrets.GH_USER_TOKEN }}
    steps:
      - name: Checkout repo (for scripts)
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install deps
        run: npm ci
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: junit-*
          merge-multiple: false

      - name: Generate summary reports
        run: |
          set -euo pipefail
          mkdir -p test-results
          reports=()
          for target in base head merge; do
            dir="junit-${target}/test-results"
            if [ -d "${dir}" ]; then
              node src/cli/commands/detect-test-regressions.mjs summarize --input "${dir}" --output "junit-${target}"
              reports+=("${target}=junit-${target}/summary.json")
            fi
          done
          if [ ${#reports[@]} -ge 2 ]; then
            node src/cli/commands/detect-test-regressions.mjs compare "${reports[@]}" --output test-results
          fi

      # Use your repo’s logic to compute regressions (allows legacy failures)
      - name: Detect regressions (repo script)
        id: regress
        env:
          COMPARISON_PATH: ${{ github.workspace }}/test-results/comparison.json
        run: |
          if [ ! -f "${COMPARISON_PATH}" ]; then
            echo "::warning::Comparison report not found; treating as error."
            {
              echo "all_green=false"
              echo "status=error"
            } >> "$GITHUB_OUTPUT"
            exit 0
          fi
          node --input-type=module <<'EOF'
          import fs from 'node:fs';

          const comparisonPath = process.env.COMPARISON_PATH;
          const outputPath = process.env.GITHUB_OUTPUT;

          let data;
          let comparisons = [];
          try {
            const raw = fs.readFileSync(comparisonPath, 'utf8');
            data = JSON.parse(raw);
            comparisons = Array.isArray(data.comparisons) ? data.comparisons : [];
          } catch (err) {
            console.error(`::error::Failed to read or parse comparison file at ${comparisonPath}: ${err.message}`);
            if (outputPath) {
              fs.appendFileSync(outputPath, `all_green=false\n`);
              fs.appendFileSync(outputPath, `status=error\n`);
            }
            process.exit(0);
          }

          let status = 'clean';
          let allGreen = true;

          if (comparisons.length === 0) {
            status = 'error';
            allGreen = false;
          } else if (comparisons.some((entry) => entry?.regressions?.hasRegression)) {
            status = 'regressions';
            allGreen = false;
          }

          if (outputPath) {
            fs.appendFileSync(outputPath, `all_green=${allGreen ? 'true' : 'false'}\n`);
            fs.appendFileSync(outputPath, `status=${status}\n`);
          }
          EOF

      - name: Summarize and comment
        uses: actions/github-script@v7
        env:
          REGRESSION_ALL_GREEN: ${{ steps.regress.outputs.all_green }}
          REGRESSION_STATUS: ${{ steps.regress.outputs.status }}
        with:
          script: |
            const MARKER = '<!-- automerge-pr-test-summary -->';
            const fs = require('node:fs');
            const path = require('node:path');

            const pull = context.payload.pull_request;
            const baseRef = pull?.base?.ref || 'base';
            const baseSha = (pull?.base?.sha || '').slice(0, 7) || '???????';
            const headRef = pull?.head?.ref || 'head';
            const headSha = (pull?.head?.sha || '').slice(0, 7) || '???????';

            const summaryTargets = [
              { label: 'base', title: `Base (${baseRef} @ ${baseSha})` },
              { label: 'head', title: `PR (${headRef} @ ${headSha})` },
              { label: 'merge', title: 'Merged (base+PR)' }
            ];

            const summaries = [];
            for (const target of summaryTargets) {
              const file = path.join(process.cwd(), `junit-${target.label}`, 'summary.json');
              if (!fs.existsSync(file)) {
                continue;
              }
              try {
                const data = JSON.parse(fs.readFileSync(file, 'utf8'));
                summaries.push({ ...target, data });
              } catch (error) {
                core.warning(`Failed to parse summary for ${target.label}: ${error}`);
              }
            }

            const comparisonPath = path.join(process.cwd(), 'test-results', 'comparison.json');
            let comparisons = [];
            if (fs.existsSync(comparisonPath)) {
              try {
                const parsed = JSON.parse(fs.readFileSync(comparisonPath, 'utf8'));
                if (Array.isArray(parsed.comparisons)) {
                  comparisons = parsed.comparisons;
                }
              } catch (error) {
                core.warning(`Failed to parse comparison report: ${error}`);
              }
            }

            function fmtNumber(value) {
              return typeof value === 'number' && Number.isFinite(value)
                ? value.toLocaleString('en-US')
                : '—';
            }

            function fmtCoverage(coverage) {
              if (!coverage || !Number.isFinite(coverage.pct)) {
                return '—';
              }
              return `${coverage.pct.toFixed(1)}%`;
            }

            function fmtDuration(seconds) {
              if (!Number.isFinite(seconds)) {
                return '—';
              }
              return `${seconds.toFixed(1)}s`;
            }

            const rows = [
              '| Target | Total | Passed | Failed | Skipped | Lint warnings | Lint errors | Coverage | Duration |',
              '| --- | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |'
            ];

            for (const summary of summaries) {
              const tests = summary.data?.tests ?? {};
              const lint = summary.data?.lint;
              const coverage = summary.data?.coverage;
              rows.push(
                `| ${summary.title} | ${fmtNumber(tests.total)} | ${fmtNumber(
                  tests.passed
                )} | ${fmtNumber(tests.failed)} | ${fmtNumber(
                  tests.skipped
                )} | ${fmtNumber(lint?.warnings ?? null)} | ${fmtNumber(
                  lint?.errors ?? null
                )} | ${fmtCoverage(coverage)} | ${fmtDuration(
                  tests.duration
                )} |`
              );
            }

            const regressionSummaries = comparisons
              .filter((entry) => entry?.regressions)
              .map((entry) => {
                const details = [];
                const reg = entry.regressions;
                if (reg.newFailures > 0) {
                  details.push(`${reg.newFailures} new failing test${reg.newFailures === 1 ? '' : 's'}`);
                }
                if (reg.lintErrors > 0) {
                  details.push(`${reg.lintErrors} additional lint error${reg.lintErrors === 1 ? '' : 's'}`);
                }
                if (typeof reg.coverageDrop === 'number' && reg.coverageDrop > 0) {
                  details.push(`coverage dropped by ${reg.coverageDrop.toFixed(1)} pts`);
                }
                const suffix = details.length > 0 ? ` (${details.join(', ')})` : '';
                return `- **${entry.base} → ${entry.target}**: ${reg.hasRegression ? 'regressions detected' : 'no regressions'}${suffix}`;
              });

            const statusLine = `Status: **${process.env.REGRESSION_STATUS || 'unknown'}** (all green: ${process.env.REGRESSION_ALL_GREEN || 'unknown'})`;

            const body = [
              MARKER,
              '',
              ...rows,
              '',
              statusLine,
              '',
              ...(regressionSummaries.length > 0
                ? ['Regression summary:', ...regressionSummaries]
                : []
              )
            ].join('\n');

            const { owner, repo } = context.repo;
            const issueNumber = context.payload.pull_request?.number;
            if (!issueNumber) {
              core.notice('No pull request number; skipping comment.');
              return;
            }

            const comments = await github.paginate(
              github.rest.issues.listComments,
              { owner, repo, issue_number: issueNumber, per_page: 100 }
            );

            const existing = comments.find((comment) =>
              comment?.body && comment.body.includes(MARKER)
            );

            if (existing) {
              await github.rest.issues.updateComment({
                owner,
                repo,
                comment_id: existing.id,
                body
              });
            } else {
              await github.rest.issues.createComment({
                owner,
                repo,
                issue_number: issueNumber,
                body
              });
            }
      - name: Request Codex help for regressions
        if: ${{ github.event_name == 'pull_request' && steps.regress.outputs.status == 'regressions' && env.GH_USER_TOKEN != '' }}
        uses: actions/github-script@v7
        with:
          github-token: ${{ env.GH_USER_TOKEN }}
          script: |
            const marker = '<!-- automerge-pr-regression-codex -->';
            const { owner, repo } = context.repo;
            const number = context.payload.pull_request?.number;
            if (!number) {
              core.notice('No PR number; skipping Codex regression comment.');
              return;
            }

            const { data: pr } = await github.rest.pulls.get({ owner, repo, pull_number: number });
            const comments = await github.paginate(github.rest.issues.listComments, {
              owner,
              repo,
              issue_number: number,
              per_page: 100,
            });

            const existing = comments.find(comment => comment.body && comment.body.includes(marker));

            const lines = [
              marker,
              '',
              `@codex The auto-merge workflow detected test regressions on this PR while comparing \`${pr.head.ref}\` against \`${pr.base.ref}\`. Please review the failing suites, identify the root cause, and provide the fixes or guidance needed so this change can be merged.`,
              '',
              'Suggested next steps:',
              '1. Review the "Node.js regression test summary" comment and the uploaded junit-* artifacts for detailed failure reports.',
              '2. Reproduce the failures locally (for example, `npm run test:report` and `npm run test:coverage`) to confirm the regression.',
              '3. Deliver the smallest possible fix—or a precise explanation of the required follow-up—that resolves the regression blocking auto-merge.',
              '',
              `Once done, ensure all changes are pushed to remote branch **${pr.head.ref}** on base **${pr.base.ref}** and keep all commits tied to PR #${number}; do not open new branches or PRs. As the final step (even after running 'make_pr'), run the following exact command(s) to guarantee your changes are pushed:`,
              '',
              '```bash',
              'git config user.name  "codex-bot"',
              'git config user.email "codex@example.com"',
              'git -c credential.helper= \\',
              `    -c 'credential.helper=store --file .git/codex-cred' \\',`,
              `    push "https://henrylkirk@github.com/${owner}/${repo}.git" "HEAD:${pr.head.ref}"`,
              '```',
              '',
              'Context for this request:',
              '```yaml',
              'codex_task:',
              `  branch: "${pr.head.ref}"`,
              `  pr_number: ${number}`,
              `  base: "${pr.base.ref}"`,
              `  head_sha: "${pr.head.sha}"`,
              '  reason: "automerge regression gate failure"',
              '```',
            ];

            const body = lines.join('\n');

            if (existing) {
              await github.rest.issues.updateComment({ owner, repo, comment_id: existing.id, body });
            } else {
              await github.rest.issues.createComment({ owner, repo, issue_number: number, body });
            }

            core.notice(`Requested Codex assistance for regressions on PR #${number}.`);

      - name: Warn when Codex user token missing
        if: ${{ github.event_name == 'pull_request' && steps.regress.outputs.status == 'regressions' && env.GH_USER_TOKEN == '' }}
        run: |
          echo "::warning::GH_USER_TOKEN secret is not configured; skipping Codex regression comment."

  auto-merge:
    name: Auto-merge when green
    needs: summarize
    if: ${{ github.event_name == 'pull_request' && needs.summarize.outputs.all_green == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - name: Merge PR (and delete branch if safe)
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const number = context.payload.pull_request.number;
            const loadPr = async () => (await github.rest.pulls.get({ owner, repo, pull_number: number })).data;
            const wait = ms => new Promise(resolve => setTimeout(resolve, ms));
            const allowedStates = new Set(['clean','unstable','blocked','has_hooks']);

            let pr = await loadPr();

            if (pr.draft) { core.notice(`Skip merge #${number}: draft.`); return; }

            const maxAttempts = 6;
            for (let attempt = 1; attempt <= maxAttempts; attempt++) {
              const state = String(pr.mergeable_state || '').toLowerCase();
              const mergeableKnown = pr.mergeable !== null && state && state !== 'unknown';
              if (mergeableKnown) break;

              if (attempt === maxAttempts) {
                core.notice(`Skip merge #${number}: mergeability unresolved after ${maxAttempts} attempts (mergeable=${pr.mergeable}, state=${pr.mergeable_state}).`);
                return;
              }

              core.info(`Mergeability pending for #${number} (attempt ${attempt}/${maxAttempts}): mergeable=${pr.mergeable}, state=${pr.mergeable_state}. Retrying in 5s...`);
              await wait(5000);
              pr = await loadPr();
            }

            const state = String(pr.mergeable_state || '').toLowerCase();
            const ok = pr.mergeable === true && allowedStates.has(state);
            if (!ok) { core.notice(`Skip merge #${number}: mergeable=${pr.mergeable}, state=${pr.mergeable_state}.`); return; }

            await github.rest.pulls.merge({ owner, repo, pull_number: number, merge_method: 'squash' });
            core.notice(`Auto-merged PR #${number}.`);

            // Delete head branch if safe
            try {
              const headRef = pr.head?.ref;
              const headRepoFull = pr.head?.repo?.full_name?.toLowerCase() || '';
              const thisFull = `${owner}/${repo}`.toLowerCase();
              if (!headRef || headRepoFull !== thisFull) {
                core.info(`Not deleting branch: different repo or missing ref (head=${headRepoFull}, this=${thisFull}, ref=${headRef}).`);
              } else {
                const { data: rinfo } = await github.rest.repos.get({ owner, repo });
                const defaultBranch = rinfo.default_branch;
                if (headRef === defaultBranch) {
                  core.info(`Not deleting branch: ${headRef} is the default branch.`);
                } else {
                  await github.rest.git.deleteRef({ owner, repo, ref: `heads/${headRef}` });
                  core.notice(`Deleted branch ${headRef} after merge.`);
                }
              }
            } catch (e) {
              core.warning(`Unable to delete head branch: ${e.message}`);
            }
