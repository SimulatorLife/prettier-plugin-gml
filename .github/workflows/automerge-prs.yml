name: Auto-merge PRs

on:
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    branches: [main, master, mainline]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  checks: write

concurrency:
  group: automerge-${{ github.event.pull_request.number || 'manual' }}
  cancel-in-progress: true

jobs:
  gate:
    runs-on: ubuntu-latest
    outputs:
      should_run_tests: ${{ steps.decide.outputs.should_run_tests }}
    steps:
      - id: decide
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const n = context.payload.pull_request?.number;
            if (!n) { core.setOutput('should_run_tests', 'false'); return; }
            const files = await github.paginate(github.rest.pulls.listFiles, {
              owner, repo, pull_number: n, per_page: 100
            });
            core.notice(`PR changed files: ${files.length}`);
            core.setOutput('should_run_tests', files.length > 0 ? 'true' : 'false');

  tests:
    needs: gate
    if: ${{ needs.gate.outputs.should_run_tests == 'true' }}   # <- job-level gate (will show Skipped)
    name: Run tests (${{ matrix.target }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        target: [base, head, merge]

    steps:
      - name: Resolve ref for ${{ matrix.target }}
        id: ref
        run: |
          if [ "${{ matrix.target }}" = "base" ]; then
            echo "ref=${{ github.event.pull_request.base.sha }}" >> "$GITHUB_OUTPUT"
          elif [ "${{ matrix.target }}" = "head" ]; then
            echo "ref=${{ github.sha }}" >> "$GITHUB_OUTPUT"
          else
            echo "ref=refs/pull/${{ github.event.pull_request.number }}/merge" >> "$GITHUB_OUTPUT"
          fi

      # If the synthetic merge ref doesn't exist, continue so the leg can still upload nothing and be summarized.
      - name: Checkout (${{ matrix.target }})
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.ref.outputs.ref }}
        continue-on-error: ${{ matrix.target == 'merge' }}

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install deps
        run: npm ci
        continue-on-error: ${{ matrix.target == 'merge' }}

      # Your npm script should create ./test-results/*.xml and NOT hard-exit early
      - name: Run test suite (JUnit XML)
        run: npm run test:report
        continue-on-error: true

      - name: Run coverage (LCOV)
        run: npm run test:coverage
        continue-on-error: true

      - name: Publish test summary (${{ matrix.target }})
        if: ${{ always() }}
        uses: dorny/test-reporter@v2
        with:
          name: Publish test summary (${{ matrix.target }})
          path: test-results/*.xml
          reporter: java-junit
          fail-on-error: false
          fail-on-empty: false
          use-actions-summary: false

      - name: Run lint (checkstyle)
        run: npm run lint:report
        continue-on-error: true

      - name: Upload JUnit artifacts (${{ matrix.target }})
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: junit-${{ matrix.target }}
          path: |
            test-results/*.xml
            test-results/lcov.info
          retention-days: 7

  summarize:
    name: Summarize & comment table
    needs: tests
    runs-on: ubuntu-latest
    outputs:
      all_green: ${{ steps.regress.outputs.all_green }}
    steps:
      - name: Checkout repo (for scripts)
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install deps
        run: npm ci
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: junit-*
          merge-multiple: false

      # Use your repo’s logic to compute regressions (allows legacy failures)
      - name: Detect regressions (repo script)
        id: regress
        run: |
          set +e
          set -o pipefail
          log_file="$(mktemp)"
          export BASE_RESULTS_DIR="$(pwd)/junit-base"
          export MERGE_RESULTS_DIR="$(pwd)/junit-merge"
          # Falls back to head when merge isn't available (handled by your script)
          node src/cli/commands/detect-test-regressions.mjs 2>&1 | tee "$log_file"
          code=${PIPESTATUS[0]}
          if [ $code -eq 0 ]; then
            echo "all_green=true" >> "$GITHUB_OUTPUT"
            echo "status=clean" >> "$GITHUB_OUTPUT"
          else
            echo "all_green=false" >> "$GITHUB_OUTPUT"
            if grep -q "New failing tests detected" "$log_file"; then
              echo "status=regressions" >> "$GITHUB_OUTPUT"
            else
              echo "status=error" >> "$GITHUB_OUTPUT"
            fi
          fi
          rm -f "$log_file"
          exit 0

      - name: Summarize and comment
        uses: actions/github-script@v7
        env:
          REGRESSION_ALL_GREEN: ${{ steps.regress.outputs.all_green }}
          REGRESSION_STATUS: ${{ steps.regress.outputs.status }}
        with:
          script: |
            const fs = require('node:fs');
            const path = require('node:path');

            const MARKER = '<!-- automerge-pr-test-summary -->';
            const targets = ['base','head','merge'];
            const totals = {};
            const coverage = {};
            const lint = {};
            const notes = [];

            function listFilesRecursive(root) {
              if (!fs.existsSync(root)) return [];
              const files = [];
              const stack = [root];
              while (stack.length > 0) {
                const current = stack.pop();
                const entries = fs.readdirSync(current, { withFileTypes: true });
                for (const entry of entries) {
                  if (entry.name === '.' || entry.name === '..') continue;
                  const fullPath = path.join(current, entry.name);
                  if (entry.isDirectory()) {
                    stack.push(fullPath);
                  } else {
                    files.push(fullPath);
                  }
                }
              }
              return files;
            }

            function readSuites(xmlFiles) {
              let t = { tests:0, failures:0, errors:0, skipped:0, time:0 };
              for (const file of xmlFiles) {
                const xml = fs.readFileSync(file,'utf8');
                const suiteAttrs = [...xml.matchAll(/<testsuite\b([^>]*)>/g)];
                for (const m of suiteAttrs) {
                  const a = m[1] || '';
                  const pick = k => (a.match(new RegExp(`${k}="([^"]*)"`)) || [])[1] ?? null;
                  const n = v => (v === null ? 0 : Number.parseFloat(v)) || 0;
                  t.tests    += n(pick('tests'));
                  t.failures += n(pick('failures'));
                  t.errors   += n(pick('errors'));
                  t.skipped  += n(pick('skipped'));
                  t.time     += n(pick('time'));
                }
              }
              return t;
            }

            function readCoverage(lcovFiles) {
              if (lcovFiles.length === 0) return null;
              let found = 0;
              let hit = 0;
              for (const file of lcovFiles) {
                const text = fs.readFileSync(file, 'utf8');
                for (const line of text.split(/\r?\n/)) {
                  if (line.startsWith('LF:')) {
                    found += Number.parseInt(line.slice(3), 10) || 0;
                  } else if (line.startsWith('LH:')) {
                    hit += Number.parseInt(line.slice(3), 10) || 0;
                  }
                }
              }
              if (found <= 0) return { found: 0, hit: hit, pct: null };
              return { found, hit, pct: (hit / found) * 100 };
            }

            function readCheckstyle(checkstyleFiles) {
              if (checkstyleFiles.length === 0) return null;
              let warnings = 0;
              let errors = 0;
              for (const file of checkstyleFiles) {
                const xml = fs.readFileSync(file, 'utf8');
                for (const match of xml.matchAll(/<error\b[^>]*severity="([^"]*)"/gi)) {
                  const severity = (match[1] || '').toLowerCase();
                  if (severity === 'warning') warnings += 1;
                  else if (severity === 'error') errors += 1;
                }
              }
              return { warnings, errors };
            }

            const fmtCoverage = data => {
              if (!data || !Number.isFinite(data.pct)) return '—';
              return `${data.pct.toFixed(1)}%`;
            };

            for (const tgt of targets) {
              const dir = path.join(process.cwd(), `junit-${tgt}`);
              const files = listFilesRecursive(dir);
              const xmlFiles = files.filter(f => f.endsWith('.xml'));
              const lcovFiles = files.filter(f => path.basename(f) === 'lcov.info');
              const checkstyleFiles = files.filter(f => /checkstyle/i.test(path.basename(f)));
              totals[tgt] = readSuites(xmlFiles);
              coverage[tgt] = readCoverage(lcovFiles);
              lint[tgt] = readCheckstyle(checkstyleFiles);
              if (xmlFiles.length === 0) notes.push(`No JUnit XML found for **${tgt}**.`);
              if (files.length > 0 && !coverage[tgt]) notes.push(`No coverage (LCOV) data found for **${tgt}**.`);
              if (files.length > 0 && checkstyleFiles.length === 0) notes.push(`No lint (checkstyle) data found for **${tgt}**.`);
            }

            const fmtTime = s => !Number.isFinite(s) || s <= 0 ? '—'
              : s < 1 ? `${(s*1000).toFixed(0)}ms`
              : s >= 60 ? `${Math.floor(s/60)}m ${(s - Math.floor(s/60)*60).toFixed(1)}s`
              : `${s.toFixed(2)}s`;

            const fmtLintCount = value => (value === null || value === undefined) ? '—' : `${value}`;

            const row = (label, t, lintData, cov) => {
              const hasAny = (t.tests + t.failures + t.errors + t.skipped) > 0;
              const coverageCell = fmtCoverage(cov);
              const lintWarningsCell = fmtLintCount(lintData?.warnings);
              const lintErrorsCell = fmtLintCount(lintData?.errors);
              if (!hasAny) return `| ${label} | — | — | — | — | ${lintWarningsCell} | ${lintErrorsCell} | ${coverageCell} | — |`;
              const failed = t.failures + t.errors;
              const passed = Math.max(0, t.tests - failed - t.skipped);
              return `| ${label} | ${t.tests} | ${passed} | ${failed} | ${t.skipped} | ${lintWarningsCell} | ${lintErrorsCell} | ${coverageCell} | ${fmtTime(t.time)} |`;
            };

            const baseRef = context.payload.pull_request?.base?.ref || 'base';
            const baseSha = (context.payload.pull_request?.base?.sha || '').slice(0,7) || '???????';
            const headRef = context.payload.pull_request?.head?.ref || 'head';
            const headSha = (context.payload.pull_request?.head?.sha || context.sha || '').slice(0,7) || '???????';

            const table = [
              '| Target | Total | Passed | Failed | Skipped | Lint warnings | Lint errors | Coverage | Duration |',
              '| --- | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |',
              row(`Base (${baseRef} @ ${baseSha})`, totals.base, lint.base, coverage.base),
              row(`PR (${headRef} @ ${headSha})`, totals.head, lint.head, coverage.head),
              row('Merged (base+PR)', totals.merge, lint.merge, coverage.merge),
              '',
              ...notes.map(n => `> ⚠️ ${n}`)
            ].join('\n');

            const statusFlag = (process.env.REGRESSION_STATUS || '').toLowerCase();
            const allGreenFlag = (process.env.REGRESSION_ALL_GREEN || '').toLowerCase() === 'true';

            let statusLine;
            if (statusFlag === 'clean' || allGreenFlag) {
              statusLine = '✅ No test regressions detected — this PR will be auto-merged.';
            } else if (statusFlag === 'regressions') {
              statusLine = '❌ Test regressions detected — auto-merge is disabled.';
            } else if (statusFlag === 'error') {
              statusLine = '⚠️ Regression checks did not complete — auto-merge is blocked.';
            } else {
              statusLine = '⚠️ Regression status unknown — auto-merge is blocked.';
            }

            const body = [ '<!-- automerge-pr-test-summary -->', '### Node.js regression test summary', '', table, '', statusLine ].join('\n');

            const { owner, repo } = context.repo;
            const number = context.payload.pull_request?.number;
            if (!number) { core.notice('No PR number; skipping comment.'); return; }

            const comments = await github.paginate(github.rest.issues.listComments, { owner, repo, issue_number: number, per_page: 100 });
            const existing = comments.find(c => c.body && c.body.includes(MARKER));
            if (existing) {
              await github.rest.issues.updateComment({ owner, repo, comment_id: existing.id, body });
            } else {
              await github.rest.issues.createComment({ owner, repo, issue_number: number, body });
            }

  auto-merge:
    name: Auto-merge when green
    needs: summarize
    if: ${{ github.event_name == 'pull_request' && needs.summarize.outputs.all_green == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - name: Merge PR (and delete branch if safe)
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const number = context.payload.pull_request.number;
            const loadPr = async () => (await github.rest.pulls.get({ owner, repo, pull_number: number })).data;
            const wait = ms => new Promise(resolve => setTimeout(resolve, ms));
            const allowedStates = new Set(['clean','unstable','blocked','has_hooks']);

            let pr = await loadPr();

            if (pr.draft) { core.notice(`Skip merge #${number}: draft.`); return; }

            const maxAttempts = 6;
            for (let attempt = 1; attempt <= maxAttempts; attempt++) {
              const state = String(pr.mergeable_state || '').toLowerCase();
              const mergeableKnown = pr.mergeable !== null && state && state !== 'unknown';
              if (mergeableKnown) break;

              if (attempt === maxAttempts) {
                core.notice(`Skip merge #${number}: mergeability unresolved after ${maxAttempts} attempts (mergeable=${pr.mergeable}, state=${pr.mergeable_state}).`);
                return;
              }

              core.info(`Mergeability pending for #${number} (attempt ${attempt}/${maxAttempts}): mergeable=${pr.mergeable}, state=${pr.mergeable_state}. Retrying in 5s...`);
              await wait(5000);
              pr = await loadPr();
            }

            const state = String(pr.mergeable_state || '').toLowerCase();
            const ok = pr.mergeable === true && allowedStates.has(state);
            if (!ok) { core.notice(`Skip merge #${number}: mergeable=${pr.mergeable}, state=${pr.mergeable_state}.`); return; }

            await github.rest.pulls.merge({ owner, repo, pull_number: number, merge_method: 'squash' });
            core.notice(`Auto-merged PR #${number}.`);

            // Delete head branch if safe
            try {
              const headRef = pr.head?.ref;
              const headRepoFull = pr.head?.repo?.full_name?.toLowerCase() || '';
              const thisFull = `${owner}/${repo}`.toLowerCase();
              if (!headRef || headRepoFull !== thisFull) {
                core.info(`Not deleting branch: different repo or missing ref (head=${headRepoFull}, this=${thisFull}, ref=${headRef}).`);
              } else {
                const { data: rinfo } = await github.rest.repos.get({ owner, repo });
                const defaultBranch = rinfo.default_branch;
                if (headRef === defaultBranch) {
                  core.info(`Not deleting branch: ${headRef} is the default branch.`);
                } else {
                  await github.rest.git.deleteRef({ owner, repo, ref: `heads/${headRef}` });
                  core.notice(`Deleted branch ${headRef} after merge.`);
                }
              }
            } catch (e) {
              core.warning(`Unable to delete head branch: ${e.message}`);
            }
